# -------------------------------
# Written by Yongxi Lu
# -------------------------------


""" Utilities to interpret automatic logs generated by the training procedure
"""

# TODO: we dont need to plot now!
# TODO: we need to save things to a file so that we can plot as much as we like!
# Just getting everything out and saving it to a .mat file would be sufficient!

import re
import numpy as np

# necessary when used without a display
import matplotlib as mpl
mpl.use('Agg')
import matplotlib.pyplot as plt

def parse_mle_and_plot(filename, splits, metric='error', output='loss.png', run_length=1, max_iters=None, epoch_size=None, max_y=None):
    """ parse the mle log for a particular split, output file at the output location """ 

    # parse from files
    iters = {}
    err = {}
    for split in splits:
        iters[split] = []
        err[split] = []
        for fn in filename:
            it, v = parse_mle(fn, split, metric)
            iters[split].append(it)
            err[split].append(v)
        # take average
        iters[split] = iters[split][0]
        err[split] = np.mean(np.dstack(err[split]), axis=2)

    # if max_iters is specified, truncate loss
    if max_iters is not None:
        for split in splits:
            end = min(max_iters, np.max(iters[split]))
            iters[split] = iters[split][:end]
            err[split] = err[split][:end]

    # perform sampling and smoothing for the training split
    if 'training' in splits and 'validation' in splits:
        A = iters['training']
        B = iters['validation']
        # sample iterations
        center_inds = np.array([i for i in xrange(len(A)) if A[i] in B], dtype=np.int32)
        iters['training'] = A[center_inds]
        # sample errors
        begins = np.maximum(0, center_inds - run_length)
        ends = np.minimum(center_inds + run_length, len(A))
        idx = np.vstack((begins, ends)).transpose()
        values = np.array([np.mean(err['training'][idx[i,0]:idx[i,1], :], axis=0) for i in xrange(len(center_inds))])
        err['training'] = values

    # convert iterations to epochs if necessary
    if epoch_size is not None:
        for split in splits:
            iters[split] = iters[split].astype(np.float32, copy=False)
            iters[split] /= epoch_size

    plot_mle_mean(iters, err, output, max_y)

def parse_mle(filename, split, metric):
    """ parse mle log for a particular split """
    
    iters = []
    err = []
    pattern = 'Round [0-9]*, Iteration [0-9]*: {} {} = [0-9.\ ]*'.format(split, metric)
    with open(filename) as f:
        data = ' '.join([line.replace('\n', '') for line in f])
        match = re.findall(pattern, data)
        for i in xrange(len(match)):
            parts = match[i].split(' = ')
            # match iterations
            iters.append(int(re.search('Iteration [0-9]+',parts[0]).group().split(' ')[1]))
            # match error rates
            err_str = re.search('[0-9.\ ]+', parts[1]).group().split()
            err.append([float(err_str[i]) for i in xrange(len(err_str))])
                    
    iters = np.array(iters)
    err = np.array(err)

    return iters, err

def plot_mle_mean(iters, err, output="loss.png", max_y=None):
    """ Plot the evolution of multi-label error as a function of training iterations """
   
    fig, ax = plt.subplots()
    ax.set_autoscale_on(False)
    max_value = 0
    max_iters = 0

    # split y axis [0, max], split x axis [0, max_iters] (if the provided max_iters is not integer, 
    # e.g. it is the number of epochs, round it)
    for split, x in iters.iteritems():
        ax.plot(x, np.mean(err[split], axis=1), label=split, linewidth=3.0)
        max_value = max(max_value, np.max(np.mean(err[split], axis=1)))
        max_iters = np.round(max(max_iters, np.max(iters[split]))).astype(np.int32)
    # if user sets maximum of y axis, use the user setting
    if max_y is not None:
        max_value = max_y

    ax.axis([0, max_iters, 0, max_value])
    legend = ax.legend(loc='best', shadow=True)

    plt.xlabel('Number of iterations')
    plt.ylabel('Error rate')
    plt.title('Multi-label error as function of training iterations')
    # save the figure
    plt.savefig(output)

if __name__ == '__main__':

    iters_train, err_train = parse_mle('test_parse.txt', 'training')
    iters_val, err_val = parse_mle('test_parse.txt', 'validation')

    print 'Parsing results for training'
    print iters_train
    print err_train
    
    print 'Parsing results for testing'
    print iters_val
    print err_val 

    iters = {'training': iters_train, 'validation': iters_val}
    err = {'training': err_train, 'validation': err_val}

    plot_mle_mean(iters, err)
